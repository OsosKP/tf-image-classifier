{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from tensorflow.keras.metrics import AUC as auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Setup</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>PreProcessing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = preprocessing.root_data_dir\n",
    "test_path = preprocessing.test_path\n",
    "train_path = preprocessing.train_path\n",
    "val_path = preprocessing.validation_path\n",
    "\n",
    "image_shape = (300, 300, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15504 images belonging to 2 classes.\n",
      "Found 6241 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.image.directory_iterator.DirectoryIterator at 0x7f206433ac10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_gen = ImageDataGenerator(fill_mode='nearest')\n",
    "image_gen.flow_from_directory(train_path)\n",
    "image_gen.flow_from_directory(test_path)\n",
    "image_gen.flow_from_directory(val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Building a Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Dropout, Flatten, Layer, concatenate, GlobalAveragePooling2D,Activation, Softmax\n",
    "from tensorflow.keras.metrics import Accuracy, AUC, Recall, Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fire_module(Layer):\n",
    "    \n",
    "    def __init__(self, squeeze_size=16, expand_size=64):\n",
    "        super(fire_module, self).__init__()\n",
    "        self.squeeze = Conv2D(filters=squeeze_size, kernel_size=(1,1), padding='valid', \\\n",
    "                              activation='relu', name=\"sq1x1\")\n",
    "        self.exp1_1 = Conv2D(filters=expand_size, kernel_size=(1,1), padding='valid', \\\n",
    "                             activation='relu', name=\"exp1x1\")\n",
    "        self.exp3_3 = Conv2D(filters=expand_size, kernel_size=(3,3), padding='same', \\\n",
    "                             activation='relu', name=\"exp3x3\")\n",
    "    \n",
    "    def call(self, input):\n",
    "        squeezed_value = self.squeeze(input)\n",
    "        exp1_1_value = self.exp1_1(squeezed_value)\n",
    "        exp3_3_value = self.exp3_3(squeezed_value)\n",
    "        return concatenate([exp1_1_value, exp3_3_value], axis=-1, name='concat')\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({\n",
    "            'squeeze': self.squeeze,\n",
    "            'exp1_1': self.exp1_1,\n",
    "            'exp3_3': self.exp3_3\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(expand_values, pooling_kernal):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=8, kernel_size=(3,3), input_shape=image_shape, activation='relu'))\n",
    "    \n",
    "    for expand_value in expand_values:\n",
    "        model.add(fire_module(int((3*expand_value)/4),expand_value))\n",
    "        model.add(MaxPool2D(pool_size=pooling_kernal))\n",
    "    \n",
    "    model.add(Conv2D(filters=1, kernel_size=(1,1), activation='sigmoid'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.compile(loss=loss_param, optimizer=optimizer_param,\n",
    "                metrics=[AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_param = 'binary_crossentropy'\n",
    "optimizer_param = 'adam'\n",
    "stop_monitor = 'val_auc'\n",
    "stop_mode = 'max'\n",
    "stop_patience = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Regularization</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize(batch_size):\n",
    "    data = {}\n",
    "    data['early_stop'] = EarlyStopping(monitor=stop_monitor, mode=stop_mode, patience=stop_patience)\n",
    "    data['train_image_gen'] = image_gen.flow_from_directory(train_path,\n",
    "                                               target_size = image_shape[:2],\n",
    "                                               batch_size = batch_size,\n",
    "                                               class_mode = 'binary')\n",
    "    data['test_image_gen'] = image_gen.flow_from_directory(test_path,\n",
    "                                               target_size=image_shape[:2],\n",
    "                                               batch_size = batch_size,\n",
    "                                               class_mode='binary',\n",
    "                                               shuffle=False)# Don't want to shuffle test data and lose labels\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Recording</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_record(model, batch_size):\n",
    "    losses = model.history.history\n",
    "    losses['loss'] = np.asarray(losses['loss'])\n",
    "    losses['val_loss'] = np.asarray(losses['val_loss'])\n",
    "    final_number_of_epochs = len(losses['loss'])\n",
    "    min_loss = losses['loss'].min()\n",
    "    mean_loss = losses['loss'].mean()\n",
    "    final_loss = losses['loss'][-1]\n",
    "    min_val_loss = losses['val_loss'].min()\n",
    "    mean_val_loss = losses['val_loss'].mean()\n",
    "    final_val_loss = losses['val_loss'][-1]\n",
    "\n",
    "    output = []\n",
    "    model.summary(print_fn=lambda line: output.append(line))\n",
    "    summary = str(output).strip('[]')\n",
    "\n",
    "    record = {\n",
    "        'Epochs': final_number_of_epochs,\n",
    "        'Batch_Size': batch_size,\n",
    "        'Loss_Func': loss_param,\n",
    "        'Optimizer': optimizer_param,\n",
    "        'Early_Stop_Monitor': stop_monitor,\n",
    "        'Early_Stop_Patience': stop_patience,\n",
    "        'Min_Loss': min_loss,\n",
    "        'Mean_Loss': mean_loss,\n",
    "        'Final_Loss': final_loss,\n",
    "        'Min_Val_Loss': min_val_loss,\n",
    "        'Mean_Val_Loss': mean_val_loss,\n",
    "        'Final_Val_Loss': final_val_loss,\n",
    "        'Model': summary\n",
    "    }\n",
    "\n",
    "    new_data = pd.DataFrame(record, index=[0])\n",
    "\n",
    "    if os.path.exists('results.csv'):\n",
    "        df_records = pd.read_csv('results.csv')\n",
    "        df_records = df_records.append(new_data)\n",
    "    else:\n",
    "        df_records = pd.DataFrame(new_data)\n",
    "\n",
    "    df_records.to_csv('results.csv', float_format='%g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Running the Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(expand_values, pooling_kernel, batch_size):\n",
    "    model = build_model(expand_values, pooling_kernel)\n",
    "    data = regularize(batch_size)\n",
    "    return model, model.fit(data['train_image_gen'], epochs=1,\n",
    "                             validation_data=data['test_image_gen'],\n",
    "                    callbacks=[data['early_stop']]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15504 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Kelsey\n",
    "'''\n",
    "Dont run yet \n",
    "TODO: make run_test take in data to work on so this test can work with un processed data\n",
    "'''\n",
    "batch_size = 64\n",
    "model, results = run_test([8],(4,4),batch_size)\n",
    "print(model.summary)\n",
    "create_record(model,batch_size)\n",
    "\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics.plot()\n",
    "metrics[['auc', 'val_auc']].plot()\n",
    "\n",
    "model.save('model1.h5')#change this for every test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kelsey\n",
    "batch_size = 64\n",
    "model, results = run_test([8,16],(3,3),batch_size)\n",
    "print(model.summary)\n",
    "create_record(model,batch_size)\n",
    "\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics.plot()\n",
    "metrics[['auc', 'val_auc']].plot()\n",
    "\n",
    "model.save('model2.h5')#change this for every test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#George\n",
    "batch_size = 64\n",
    "model, results = run_test([8,16,24],(3,3),batch_size)\n",
    "print(model.summary)\n",
    "create_record(model,batch_size)\n",
    "\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics.plot()\n",
    "metrics[['auc', 'val_auc']].plot()\n",
    "\n",
    "model.save('model3.h5')#change this for every test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Peter\n",
    "batch_size = 64\n",
    "model, results = run_test([8,16,24,32],(3,3),batch_size)\n",
    "print(model.summary)\n",
    "create_record(model,batch_size)\n",
    "\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics.plot()\n",
    "metrics[['auc', 'val_auc']].plot()\n",
    "\n",
    "model.save('model4.h5')#change this for every test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#George\n",
    "batch_size = 32\n",
    "model = run_test([8,16,24],(3,3),batch_size)\n",
    "print(model.summary)\n",
    "create_record(model,batch_size)\n",
    "\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics.plot()\n",
    "metrics[['auc', 'val_auc']].plot()\n",
    "\n",
    "model.save('model5.h5')#change this for every test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Peter\n",
    "batch_size = 32\n",
    "model = run_test([8,16,24,32],(3,3),batch_size)\n",
    "print(model.summary)\n",
    "create_record(model,batch_size)\n",
    "\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics.plot()\n",
    "metrics[['auc', 'val_auc']].plot()\n",
    "\n",
    "model.save('model6.h5')#change this for every test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after first ones\n",
    "#George\n",
    "batch_size = 64\n",
    "model = run_test([8,16,24],(2,2),batch_size)\n",
    "print(model.summary)\n",
    "create_record(model,batch_size)\n",
    "\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics.plot()\n",
    "metrics[['auc', 'val_auc']].plot()\n",
    "\n",
    "model.save('model7.h5')#change this for every test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kelsey\n",
    "batch_size = 64\n",
    "model = run_test([8,16,24,32],(2,2),batch_size)\n",
    "print(model.summary)\n",
    "create_record(model,batch_size)\n",
    "\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics.plot()\n",
    "metrics[['auc', 'val_auc']].plot()\n",
    "\n",
    "model.save('model8.h5')#change this for every test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Peter\n",
    "batch_size = 64\n",
    "model = run_test([8,16,24,32,40],(2,2),batch_size)\n",
    "print(model.summary)\n",
    "create_record(model,batch_size)\n",
    "\n",
    "metrics = pd.DataFrame(model.history.history)\n",
    "metrics.plot()\n",
    "metrics[['auc', 'val_auc']].plot()\n",
    "\n",
    "model.save('model9.h5')#change this for every test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
